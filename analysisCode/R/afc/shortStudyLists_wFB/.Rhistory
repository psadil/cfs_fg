x <= seq(from=0, to=1, by = .0001)
x <- seq(from=0, to=1, by = .0001)
y<-log(1/x)
plot(x,y)
x <- seq(from=0, to=1, by = .00001)
y<-log(1/x)
plot(x,y)
6^4
6^4
15*6^4
50^2
200^2
200^2-15*6^4
100^2-15*6^4
150^2-15*6^4
200^2-15*6^4
200^2-24*6^4
q()
25*72
4^8
4^8 - 200^2
4^8 - 300^2
R.home('bin')
install.packages('knitr')
install.packages('rnw')
install.packages('rwn')
library(knitr)
library(rnw)
install.packages('kntr')
install.packages('xtable')
install.packages('ktable')
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
?kable
corr1 = 38.41 * (2 / 512.31); corr1
corr2 = 25 * (23.17 / 8.44); corr2
corr1 = 38.41 * (2 / 512.31); corr1
corr2 = .25 * (23.17 / 8.44); corr2
- a
mu <- 70
s <- 3
r <- .5
h <- 76
yHat <- mu + r*(s/s)*(h - mu); yHat
install.packages('readxl')
```{r setup, include=FALSE,echo=FALSE,warning=FALSE}
# preamble
library(ggplot2)
library(plyr)
library(gridExtra)
source("C:/Users/admin/Documents/R/fns.R")
setwd("C:/Users/admin/googleDrive/uMass/firstYear/behavioralExpts/pSadil/processDissociation/CFS/cfs_fg/analysisCode/R/afc/shortStudyLists_wFB")
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
# preliminary changing of folders
#setwd("D:/googleDrive/uMass/firstYear/behavioralExpts/pSadil/processDissociation/CFS/analysisCode/R/afc/shortStudyLists")
wd <- getwd()
dataFile <- paste(wd, "/cfs_obj_2afc_ss1_wFB_noCheck.dat", sep="")
# find the data that was generated from the matlab files
data <- read.csv(dataFile)
# add 1 to study resp because participants were instructed to use 0-3
#data[data$studyResp3==1e+05,]$studyResp3 = 1
#data$studyResp3 <- as.factor(data$studyResp3)
nConds = max(data$condition,na.rm=TRUE)
nPAS = max(data[data$studyResp < 1000,]$studyResp,na.rm=TRUE) + 1
nItems = max(data$whichItem,na.rm=TRUE)
nSubs = max(data$subject,na.rm=TRUE)
nTrials = max(data$trial,na.rm=TRUE)
nInCond = nItems / nConds
# number of items in each condition, first presentation
nPerCond = nItems/nConds
data[data$condition==1,]$condition = 'a_foil'
data[data$condition==2,]$condition = 'b_word'
data[data$condition==3,]$condition = 'c_cfs'
data[data$condition==4,]$condition = 'd_binocular'
data$trial = as.factor(data$trial)
data$whichItem = as.factor(data$whichItem)
data$subject = as.factor(data$subject)
data$condition = as.factor(data$condition)
data$studyResp = as.factor(data$studyResp)
data$studyResp2 = as.factor(data$studyResp2)
data$studyResp3 = as.factor(data$studyResp3)
#data$condition = as.numeric(data$condition)
# don't want PAS as a factor, because there are
# vastly different numbers of each kind of response
# Do I want condition as factor? if it were, that would
# seem to make stronger claims (justified) about higher levels
# leading to higher recall rates
studyConds <- c("foil","word","cfs","binoc")
cols <- c('black', 'cornflowerblue', 'darkgoldenrod1', 'red')
pasResps <- c("0","1","2","3")
# trim away missing values (there aren't, currently)
data_trim <- na.omit(data)
cutoff = 3 # only look at CFS with PAS 2 or 1
nPresent = 3 # presented 3 times
nStudy = nTrials * nPresent
pd <- position_dodge(0.001)
# name_pas4 <- withinSubError(data_trim,4,nConds)
# name_pas3 <- withinSubError(data_trim,3,nConds)
# name_pas2 <- withinSubError(data_trim,2,nConds)
# name_pas1 <- withinSubError(data_trim,1,nConds)
# sem <- rbind(name_pas1$sem_cf,name_pas2$sem_cf,name_pas3$sem_cf,name_pas4$sem_cf)
# tPlot <- rbind(name_pas1$y_sj,name_pas2$y_sj,name_pas3$y_sj,name_pas4$y_sj)
#
# data_plot <- data_trim
# data_plot[data_plot$studyResp3==1e+05,]$studyResp3 = 1
# data_plot$studyResp3 <- as.factor(data_plot$studyResp3)
# #data_plot$studyResp3 == as.double(data_plot$studyResp3)
#
dfwc3 <- summarySEwithin(data, measurevar="named"
, withinvars=c("condition","studyResp3"),
idvar="subject", na.rm=FALSE, conf.interval=.95)
dfwc3<-ddply(dfwc3,.(condition),transform,prop=N/sum(N))
dfwc1 <- summarySEwithin(data, measurevar="named"
, withinvars=c("condition","studyResp"),
idvar="subject", na.rm=FALSE, conf.interval=.95)
dfwc1<-ddply(dfwc1,.(condition),transform,prop=N/sum(N))
first <- seq(from=1, to = nItems, by = 16)
second <- seq(from=16, to = nItems, by = 16)
nBlocks <- nItems / 16
items_named <- summarySEwithin(data, measurevar="named"
, withinvars=c("condition","whichItem"),
idvar="whichItem", na.rm=FALSE, conf.interval=.95)
items_afc <- summarySEwithin(data, measurevar="afc"
, withinvars=c("condition","whichItem"),
idvar="whichItem", na.rm=FALSE, conf.interval=.95)
toPlot_item <- cbind(named=items_named$named
,named_norm=items_named$named_norm
,ci_named=items_named$ci
,items_afc
,count=(items_afc$N+items_named$N)/2)
items_named_avg <- summarySEwithin(data, measurevar="named"
, withinvars=c("whichItem"),
idvar="whichItem", na.rm=FALSE, conf.interval=.95)
items_afc_avg <- summarySEwithin(data, measurevar="afc"
, withinvars=c("whichItem"),
idvar="whichItem", na.rm=FALSE, conf.interval=.95)
toPlot_item_avg <- cbind(named=items_named_avg$named
,named_norm=items_named_avg$named_norm
,ci_named=items_named_avg$ci
,items_afc_avg
,count=(items_afc_avg$N+items_named_avg$N)/2)
logit(1)
logit(.5)
logit(.8)
logit(.9)
toPlot_item_avg
na.rm = TRUE
toPlot_item_avgLogit <- ddply(toPlot_item_avg, c('whichItem'), .drop=TRUE,
.fun = function(xx, col, na.rm) {
c(namedLogit = logit(xx[,col]))
},
'named',
na.rm
)
toPlot_item_avgLogit
toPlot_item_avg.namedLogit <- ddply(toPlot_item_avg, c('whichItem'), .drop=TRUE,
.fun = function(xx, col, na.rm) {
c(namedLogit = logit(xx[,col]))
},
'named',
na.rm
)
toPlot_item_avg.afcLogit <- ddply(toPlot_item_avg, c('whichItem'), .drop=TRUE,
.fun = function(xx, col, na.rm) {
c(afcLogit = logit(xx[,col]))
},
'afc',
na.rm
)
toPlot_item_avg <- merge(toPlot_item_avg, toPlot_item_avg.namedLogit,toPlot_item_avg.afcLogit)
toPlot_item_avg.namedLogit
toPlot_item_avg.afcLogit
toPlot_item_avg <- merge(toPlot_item_avg, toPlot_item_avg.namedLogit)
toPlot_item_avg <- merge(toPlot_item_avg, toPlot_item_avg.afcLogit)
toPlot_item_avg
ggplot(toPlot_item_avg, aes(x=afcLogit, y=namedLogit)) +
# geom_errorbar(aes(ymin=named-ci_named, ymax=named+ci_named), colour="black", width=.05, position=pd) +
# geom_errorbarh(aes(xmin=afc-ci, xmax=afc+ci), colour="black", height = .05, position=pd) +
geom_point(position=pd, aes(size=count))  +  # count
# scale_size_continuous(breaks=c(50,100,150,200)) +
# facet_grid(. ~ condition ) +
coord_cartesian(xlim = c(0, 1), ylim = c(0,1)) +
scale_y_continuous(breaks=c(0,1)) +
scale_x_continuous(breaks=c(0,1)) +
# facet_wrap(~ condition, ncol=2) +
ggtitle("state trace, item, logit transformed scores") +
# ylim(0,1) +
# xlim(0,1) +
theme(aspect.ratio = 1) +
theme(axis.ticks = element_blank())
# theme(axis.ticks = element_blank(), axis.text.y = element_blank())
toPlot_item_avg
ggplot(toPlot_item_avg, aes(x=afcLogit, y=namedLogit)) +
# geom_errorbar(aes(ymin=named-ci_named, ymax=named+ci_named), colour="black", width=.05, position=pd) +
# geom_errorbarh(aes(xmin=afc-ci, xmax=afc+ci), colour="black", height = .05, position=pd) +
geom_point(position=pd, aes(size=count))  +  # count
# scale_size_continuous(breaks=c(50,100,150,200)) +
# facet_grid(. ~ condition ) +
coord_cartesian(xlim = c(-3, 3), ylim = c(-3,3)) +
scale_y_continuous(breaks=c(-3,3)) +
scale_x_continuous(breaks=c(-3,3)) +
# facet_wrap(~ condition, ncol=2) +
ggtitle("state trace, item, logit transformed scores") +
# ylim(0,1) +
# xlim(0,1) +
theme(aspect.ratio = 1) +
theme(axis.ticks = element_blank())
# theme(axis.ticks = element_blank(), axis.text.y = element_blank())
toPlot_item_avg$afcLogit
toPlot_item_avg$namedLogit
ggplot(toPlot_item_avg, aes(x=afcLogit, y=namedLogit)) +
# geom_errorbar(aes(ymin=named-ci_named, ymax=named+ci_named), colour="black", width=.05, position=pd) +
# geom_errorbarh(aes(xmin=afc-ci, xmax=afc+ci), colour="black", height = .05, position=pd) +
geom_point(position=pd, aes(size=count))  +  # count
# scale_size_continuous(breaks=c(50,100,150,200)) +
# facet_grid(. ~ condition ) +
coord_cartesian(xlim = c(-3, 3), ylim = c(-3,3)) +
scale_y_continuous(breaks=c(-3,3)) +
scale_x_continuous(breaks=c(-3,3)) +
# facet_wrap(~ condition, ncol=2) +
ggtitle("state trace, item, logit transformed scores") +
# ylim(0,1) +
# xlim(0,1) +
theme(aspect.ratio = 1) +
theme(axis.ticks = element_blank())
# theme(axis.ticks = element_blank(), axis.text.y = element_blank())
scale_y_continuous(breaks=c(-3,3)) +
pd
# preliminary changing of folders
#setwd("D:/googleDrive/uMass/firstYear/behavioralExpts/pSadil/processDissociation/CFS/analysisCode/R/afc/shortStudyLists")
wd <- getwd()
dataFile <- paste(wd, "/cfs_obj_2afc_ss1_wFB_noCheck.dat", sep="")
# find the data that was generated from the matlab files
data <- read.csv(dataFile)
# add 1 to study resp because participants were instructed to use 0-3
#data[data$studyResp3==1e+05,]$studyResp3 = 1
#data$studyResp3 <- as.factor(data$studyResp3)
nConds = max(data$condition,na.rm=TRUE)
nPAS = max(data[data$studyResp < 1000,]$studyResp,na.rm=TRUE) + 1
nItems = max(data$whichItem,na.rm=TRUE)
nSubs = max(data$subject,na.rm=TRUE)
nTrials = max(data$trial,na.rm=TRUE)
nInCond = nItems / nConds
# number of items in each condition, first presentation
nPerCond = nItems/nConds
data[data$condition==1,]$condition = 'a_foil'
data[data$condition==2,]$condition = 'b_word'
data[data$condition==3,]$condition = 'c_cfs'
data[data$condition==4,]$condition = 'd_binocular'
data$trial = as.factor(data$trial)
data$whichItem = as.factor(data$whichItem)
data$subject = as.factor(data$subject)
data$condition = as.factor(data$condition)
data$studyResp = as.factor(data$studyResp)
data$studyResp2 = as.factor(data$studyResp2)
data$studyResp3 = as.factor(data$studyResp3)
#data$condition = as.numeric(data$condition)
# don't want PAS as a factor, because there are
# vastly different numbers of each kind of response
# Do I want condition as factor? if it were, that would
# seem to make stronger claims (justified) about higher levels
# leading to higher recall rates
studyConds <- c("foil","word","cfs","binoc")
cols <- c('black', 'cornflowerblue', 'darkgoldenrod1', 'red')
pasResps <- c("0","1","2","3")
# trim away missing values (there aren't, currently)
data_trim <- na.omit(data)
cutoff = 3 # only look at CFS with PAS 2 or 1
nPresent = 3 # presented 3 times
nStudy = nTrials * nPresent
pd <- position_dodge(0.001)
ps
pd
na.rm = TRUE
toPlot_item_avg.namedLogit <- ddply(toPlot_item_avg, c('whichItem'), .drop=TRUE,
.fun = function(xx, col, na.rm) {
c(namedLogit = logit(xx[,col]))
},
'named',
na.rm
)
toPlot_item_avg.afcLogit <- ddply(toPlot_item_avg, c('whichItem'), .drop=TRUE,
.fun = function(xx, col, na.rm) {
c(afcLogit = logit(xx[,col]))
},
'afc',
na.rm
)
toPlot_item_avg <- merge(toPlot_item_avg, toPlot_item_avg.namedLogit)
toPlot_item_avg <- merge(toPlot_item_avg, toPlot_item_avg.afcLogit)
ggplot(toPlot_item_avg, aes(x=afcLogit, y=namedLogit)) +
# geom_errorbar(aes(ymin=named-ci_named, ymax=named+ci_named), colour="black", width=.05, position=pd) +
# geom_errorbarh(aes(xmin=afc-ci, xmax=afc+ci), colour="black", height = .05, position=pd) +
geom_point(position=pd, aes(size=count))  +  # count
coord_cartesian(xlim = c(-3, 3), ylim = c(-3,3)) +
scale_y_continuous(breaks=c(-3,3)) +
scale_x_continuous(breaks=c(-3,3)) +
ggtitle("state trace, item, logit transformed scores") +
theme(aspect.ratio = 1) +
theme(axis.ticks = element_blank())
toPlot_item_avg
ggplot(toPlot_item_avg[toPlot_item_avg$afcLogit != Inf &toPlot_item_avg$namedLogit != -Inf,], aes(x=afcLogit, y=namedLogit)) +
# geom_errorbar(aes(ymin=named-ci_named, ymax=named+ci_named), colour="black", width=.05, position=pd) +
# geom_errorbarh(aes(xmin=afc-ci, xmax=afc+ci), colour="black", height = .05, position=pd) +
geom_point(position=pd, aes(size=count))  +  # count
coord_cartesian(xlim = c(-3, 3), ylim = c(-3,3)) +
scale_y_continuous(breaks=c(-3,3)) +
scale_x_continuous(breaks=c(-3,3)) +
ggtitle("state trace, item, logit transformed scores") +
theme(aspect.ratio = 1) +
theme(axis.ticks = element_blank())
ggplot(toPlot_item_avg[toPlot_item_avg$afcLogit != Inf &toPlot_item_avg$namedLogit != -Inf,], aes(x=afcLogit, y=namedLogit)) +
# geom_errorbar(aes(ymin=named-ci_named, ymax=named+ci_named), colour="black", width=.05, position=pd) +
# geom_errorbarh(aes(xmin=afc-ci, xmax=afc+ci), colour="black", height = .05, position=pd) +
geom_point(position=pd, aes(size=count))  +  # count
coord_cartesian(xlim = c(-4, 4), ylim = c(-4,4)) +
scale_y_continuous(breaks=c(-4,4)) +
scale_x_continuous(breaks=c(-4,4)) +
ggtitle("state trace, item, logit transformed scores") +
theme(aspect.ratio = 1) +
theme(axis.ticks = element_blank())
max(toPlot_item_avg$afcLogit)
max(toPlot_item_avg[toPlot_item_avg$afcLogit != Inf &toPlot_item_avg$namedLogit != -Inf,afcLogit])
max(toPlot_item_avg[toPlot_item_avg$afcLogit != Inf &toPlot_item_avg$namedLogit != -Inf,'afcLogit'])
max(toPlot_item_avg[toPlot_item_avg$afcLogit != Inf &toPlot_item_avg$namedLogit != -Inf,'namedLogit'])
max(toPlot_item_avg[toPlot_item_avg$afcLogit != Inf & toPlot_item_avg$namedLogit != -Inf & toPlot_item_avg$namedLogit != Inf,'namedLogit'])
min(toPlot_item_avg[toPlot_item_avg$afcLogit != Inf &toPlot_item_avg$namedLogit != -Inf,'afcLogit'])
na.rm = TRUE
toPlot_item_avg.namedLogit <- ddply(toPlot_item_avg, c('whichItem'), .drop=TRUE,
.fun = function(xx, col, na.rm) {
c(namedLogit = logit(xx[,col]))
},
'named',
na.rm
)
toPlot_item_avg.afcLogit <- ddply(toPlot_item_avg, c('whichItem'), .drop=TRUE,
.fun = function(xx, col, na.rm) {
c(afcLogit = logit(xx[,col]))
},
'afc',
na.rm
)
toPlot_item_avg <- merge(toPlot_item_avg, toPlot_item_avg.namedLogit)
toPlot_item_avg <- merge(toPlot_item_avg, toPlot_item_avg.afcLogit)
ggplot(toPlot_item_avg[toPlot_item_avg$afcLogit != Inf & toPlot_item_avg$namedLogit != -Inf & toPlot_item_avg$namedLogit != Inf,], aes(x=afcLogit, y=namedLogit)) +
# geom_errorbar(aes(ymin=named-ci_named, ymax=named+ci_named), colour="black", width=.05, position=pd) +
# geom_errorbarh(aes(xmin=afc-ci, xmax=afc+ci), colour="black", height = .05, position=pd) +
geom_point(position=pd, aes(size=count))  +  # count
coord_cartesian(xlim = c(-4, 4), ylim = c(-4,4)) +
scale_y_continuous(breaks=c(-4,4)) +
scale_x_continuous(breaks=c(-4,4)) +
ggtitle("state trace, item, logit transformed scores") +
theme(aspect.ratio = 1) +
theme(axis.ticks = element_blank())
