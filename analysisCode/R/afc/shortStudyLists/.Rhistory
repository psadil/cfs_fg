(data_fin[data_fin$a==tmp,]$value
)
a.ss <- 0
for (tmp in 1:4){
a.ss <- a.ss + sum((data_fin[data_fin$a==tmp,]$value-mu)^2)
}
a.ss
sumsq
b.ss <- 0
for (tmp in 1:4){
b.ss <- b.ss + sum((data_fin[data_fin$b==tmp,]$value-mu)^2)
}
b.ss
data_fin
data_fin<-cbind(data_melt
,as.factor(rep(c(t(g)),each=n))
,as.factor(rep(1:4,each=20))
)
names(data_fin)[4] = 'a'
names(data_fin)[5] = 'g'
data_fin
g.ss <- 0
for (tmp in 1:4){
g.ss <- g.ss + sum((data_fin[data_fin$g==tmp,]$value-mu)^2)
}
g.ss
a[g]
length(a[g])
a[g]+mu+b
?as.matrix
as.matrix(a[g]+mu+b,nrow=4,ncol=4)
a[g]+mu+b
as.matrix(a[g]+mu+b)
as.matrix(a[g]+mu+b,nrow=4,ncol=4)
as.matrix(a[g]+mu+b,nrow=4,ncol=4,byrow=TRUE)
array(g)
array(g,dim=c(4,4))
array(a[g]+mu+b,dim=c(4,4))
g.ss
ab <- rbind(c(2,1,-2,-2),c(0,-2,0,-3),c(-3,-3,-2,3),c(1,4,4,2))
data_c <- array(a[g]+mu+b+ab,dim=c(4,4))
data_ab
data_c
df <- data.frame(data_c)
names(df)[1] <- 'b1'
names(df)[2] <- 'b2'
names(df)[3] <- 'b3'
df_c <- cbind(df_c_more,subs)
df_c_more <- df[rep(seq_len(nrow(df_c)), each=n),]
df_c <- cbind(df_c_more,subs)
data_c_melt <- melt(df_c,id.vars='subs'
, measure.vars=c('b1','b2','b3','b3')
, variable.name = 'b'
)
df_c_more <- df_c[rep(seq_len(nrow(df_c)), each=n),]
ab <- rbind(c(2,1,-2,-2),c(0,-2,0,-3),c(-3,-3,-2,3),c(1,4,4,2))
data_c <- array(a[g]+mu+b+ab,dim=c(4,4))
df_c <- data.frame(data_c)
names(df_c)[1] <- 'b1'
names(df_c)[2] <- 'b2'
names(df_c)[3] <- 'b3'
names(df_c)[4] <- 'b4'
df_c_more <- df_c[rep(seq_len(nrow(df_c)), each=n),]
df_c <- cbind(df_c_more,subs)
data_c_melt <- melt(df_c,id.vars='subs'
, measure.vars=c('b1','b2','b3','b3')
, variable.name = 'b'
)
data_c_fin<-cbind(data_c_melt
,as.factor(rep(c(t(g)),each=n))
,as.factor(rep(1:4,each=20))
)
names(data_c_fin)[4] = 'a'
names(data_c_fin)[5] = 'g'
a.ss <- 0
for (tmp in 1:4){
a.ss <- a.ss + sum((data_fin[data_fin$a==tmp,]$value-mu)^2)
}
a.ss
b.ss <- 0
for (tmp in 1:4){
b.ss <- b.ss + sum((data_fin[data_fin$b==tmp,]$value-mu)^2)
}
b.ss
g.ss <- 0
for (tmp in 1:4){
g.ss <- g.ss + sum((data_fin[data_fin$g==tmp,]$value-mu)^2)
}
g.ss
a_c.ss <- 0
for (tmp in 1:4){
a.ss <- a_c.ss + sum((data_c_fin[data_c_fin$a==tmp,]$value-mu)^2)
}
a_c.ss
b_c.ss <- 0
for (tmp in 1:4){
b_c.ss <- b_c.ss + sum((data_c_fin[data_c_fin$b==tmp,]$value-mu)^2)
}
b_c.ss
g_c.ss <- 0
for (tmp in 1:4){
g_c.ss <- g_c.ss + sum((data_c_fin[data_c_fin$g==tmp,]$value-mu)^2)
}
g_c.ss
setwd("D:/googleDrive/uMass/firstYear/behavioralExpts/pSadil/processDissociation/CFS/cfs_fg/analysisCode/R/afc/shortStudyLists")
dfwc
library(ggplot2)
library(plyr)
error.bar <- function(x, y, upper, lower=upper, length=0.1,...){
if(length(x) != length(y) | length(y) !=length(lower) | length(lower) != length(upper))
stop("vectors must be same length")
arrows(x,y+upper, x, y-lower, angle=90, code=3, length=length, ...)
}
logit<-function(x){
y <- log(x/(1-x))
return(y)
}
withinSubError <- function(df, pas, nConds){
x_sj <- aggregate( named ~
subject:condition
,data=df[df$studyResp3==pas,],FUN='mean')
x_s <- aggregate( named ~
subject
,data=df[df$studyResp3==pas,],FUN='mean')
x <- mean(df$named)
nSubs <- max(as.double(x_sj$subject))
y_sj <- data.frame(subject=rep(1:nSubs,each=nConds)
,condition=rep(1:nConds,times=nSubs)
,named=rep(0,nSubs*nConds)
)
for (sub in 1:nSubs) {
for (cond in 1:nConds){
if(length(x_sj[x_sj$subject==sub & x_sj$condition==cond,]$named)!=0){
y_sj[y_sj$subject==sub
& y_sj$condition==cond,]$named <- x_sj[x_sj$subject==sub
& x_sj$condition==cond,]$named -
x_s[x_s$subject==sub,]$named + x
}
}
}
# correction factor
sem_cf <- sqrt(aggregate(named ~ condition,data=y_sj,FUN='var')$named *
(nConds / (nConds-1))) / sqrt(nSubs)
# also grab original sem
sem <- sqrt(aggregate(named ~ condition,data=x_sj,FUN='var')$named) / sqrt(nSubs)
result = list(y_sj=y_sj,sem=sem,sem_cf=sem_cf)
return(result)
}
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
## Norms the data within specified groups in a data frame; it normalizes each
## subject (identified by idvar) so that they have the same mean, within each group
## specified by betweenvars.
##   data: a data frame.
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   na.rm: a boolean that indicates whether to ignore NA's
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
na.rm=FALSE, .drop=TRUE) {
library(plyr)
# Measure var on left, idvar + between vars on right of formula.
data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
.fun = function(xx, col, na.rm) {
c(subjMean = mean(xx[,col], na.rm=na.rm))
},
measurevar,
na.rm
)
# Put the subject means with original data
data <- merge(data, data.subjMean)
# Get the normalized data in a new column
measureNormedVar <- paste(measurevar, "_norm", sep="")
data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
mean(data[,measurevar], na.rm=na.rm)
# Remove this subject mean column
data$subjMean <- NULL
return(data)
}
## Summarizes data, handling within-subjects variables by removing inter-subject variability.
## It will still work if there are no within-S variables.
## Gives count, un-normed mean, normed mean (with same between-group mean),
##   standard deviation, standard error of the mean, and confidence interval.
## If there are within-subject variables, calculate adjusted values using method from Morey (2008).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   withinvars: a vector containing names of columns that are within-subjects variables
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
# Ensure that the betweenvars and withinvars are factors
factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
FUN=is.factor, FUN.VALUE=logical(1))
if (!all(factorvars)) {
nonfactorvars <- names(factorvars)[!factorvars]
message("Automatically converting the following non-factors to factors: ",
paste(nonfactorvars, collapse = ", "))
data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
}
# Get the means from the un-normed data
datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Drop all the unused columns (these will be calculated with normed data)
datac$sd <- NULL
datac$se <- NULL
datac$ci <- NULL
# Norm each subject's data
ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
# This is the name of the new column
measurevar_n <- paste(measurevar, "_norm", sep="")
# Collapse the normed data - now we can treat between and within vars the same
ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Apply correction from Morey (2008) to the standard error and confidence interval
#  Get the product of the number of conditions of within-S variables
nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
FUN.VALUE=numeric(1)))
correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
# Apply the correction factor
ndatac$sd <- ndatac$sd * correctionFactor
ndatac$se <- ndatac$se * correctionFactor
ndatac$ci <- ndatac$ci * correctionFactor
# Combine the un-normed means with the normed results
merge(datac, ndatac)
}
wd <- getwd()
dataFile <- paste(wd, "/cfs_obj_2afc_ss1.dat", sep="")
# find the data that was generated from the matlab files
data <- read.csv(dataFile)
# add 1 to study resp because participants were instructed to use 0-3
data$studyResp = data$studyResp+1
data$studyResp2 = data$studyResp2+1
data$studyResp3 = data$studyResp3+1
nConds = max(data$condition,na.rm=TRUE)
nPAS = max(data[data$studyResp < 1000,]$studyResp,na.rm=TRUE)
nItems = max(data$whichItem,na.rm=TRUE)
nSubs = max(data$subject,na.rm=TRUE)
nTrials = max(data$trial,na.rm=TRUE)
nInCond = nItems / nConds
# number of items in each condition, first presentation
nPerCond = nItems/nConds
data$trial = as.factor(data$trial)
data$whichItem = as.factor(data$whichItem)
data$subject = as.factor(data$subject)
data$condition = as.factor(data$condition)
#data$condition = as.numeric(data$condition)
# don't want PAS as a factor, because there are
# vastly different numbers of each kind of response
# Do I want condition as factor? if it were, that would
# seem to make stronger claims (justified) about higher levels
# leading to higher recall rates
studyConds <- c("foil","word","cfs","binoc")
cols <- c('black', 'cornflowerblue', 'darkgoldenrod1', 'red')
pasResps <- c("0","1","2","3")
# trim away missing values (there aren't, currently)
data_trim <- na.omit(data)
cutoff = 3 # only look at CFS with PAS 2 or 1
nPresent = 3 # presented 3 times
nStudy = nTrials * nPresent
dfwc <- summarySEwithin(data_plot, measurevar="named"
, withinvars=c("condition","studyResp3"),
idvar="subject", na.rm=FALSE, conf.interval=.95)
library(ggplot2)
library(plyr)
error.bar <- function(x, y, upper, lower=upper, length=0.1,...){
if(length(x) != length(y) | length(y) !=length(lower) | length(lower) != length(upper))
stop("vectors must be same length")
arrows(x,y+upper, x, y-lower, angle=90, code=3, length=length, ...)
}
logit<-function(x){
y <- log(x/(1-x))
return(y)
}
withinSubError <- function(df, pas, nConds){
x_sj <- aggregate( named ~
subject:condition
,data=df[df$studyResp3==pas,],FUN='mean')
x_s <- aggregate( named ~
subject
,data=df[df$studyResp3==pas,],FUN='mean')
x <- mean(df$named)
nSubs <- max(as.double(x_sj$subject))
y_sj <- data.frame(subject=rep(1:nSubs,each=nConds)
,condition=rep(1:nConds,times=nSubs)
,named=rep(0,nSubs*nConds)
)
for (sub in 1:nSubs) {
for (cond in 1:nConds){
if(length(x_sj[x_sj$subject==sub & x_sj$condition==cond,]$named)!=0){
y_sj[y_sj$subject==sub
& y_sj$condition==cond,]$named <- x_sj[x_sj$subject==sub
& x_sj$condition==cond,]$named -
x_s[x_s$subject==sub,]$named + x
}
}
}
# correction factor
sem_cf <- sqrt(aggregate(named ~ condition,data=y_sj,FUN='var')$named *
(nConds / (nConds-1))) / sqrt(nSubs)
# also grab original sem
sem <- sqrt(aggregate(named ~ condition,data=x_sj,FUN='var')$named) / sqrt(nSubs)
result = list(y_sj=y_sj,sem=sem,sem_cf=sem_cf)
return(result)
}
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
na.rm=FALSE, .drop=TRUE) {
library(plyr)
# Measure var on left, idvar + between vars on right of formula.
data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
.fun = function(xx, col, na.rm) {
c(subjMean = mean(xx[,col], na.rm=na.rm))
},
measurevar,
na.rm
)
# Put the subject means with original data
data <- merge(data, data.subjMean)
# Get the normalized data in a new column
measureNormedVar <- paste(measurevar, "_norm", sep="")
data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
mean(data[,measurevar], na.rm=na.rm)
# Remove this subject mean column
data$subjMean <- NULL
return(data)
}
## Summarizes data, handling within-subjects variables by removing inter-subject variability.
## It will still work if there are no within-S variables.
## Gives count, un-normed mean, normed mean (with same between-group mean),
##   standard deviation, standard error of the mean, and confidence interval.
## If there are within-subject variables, calculate adjusted values using method from Morey (2008).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   withinvars: a vector containing names of columns that are within-subjects variables
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
# Ensure that the betweenvars and withinvars are factors
factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
FUN=is.factor, FUN.VALUE=logical(1))
if (!all(factorvars)) {
nonfactorvars <- names(factorvars)[!factorvars]
message("Automatically converting the following non-factors to factors: ",
paste(nonfactorvars, collapse = ", "))
data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
}
# Get the means from the un-normed data
datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Drop all the unused columns (these will be calculated with normed data)
datac$sd <- NULL
datac$se <- NULL
datac$ci <- NULL
# Norm each subject's data
ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
# This is the name of the new column
measurevar_n <- paste(measurevar, "_norm", sep="")
# Collapse the normed data - now we can treat between and within vars the same
ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Apply correction from Morey (2008) to the standard error and confidence interval
#  Get the product of the number of conditions of within-S variables
nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
FUN.VALUE=numeric(1)))
correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
# Apply the correction factor
ndatac$sd <- ndatac$sd * correctionFactor
ndatac$se <- ndatac$se * correctionFactor
ndatac$ci <- ndatac$ci * correctionFactor
# Combine the un-normed means with the normed results
merge(datac, ndatac)
}
name_pas4 <- withinSubError(data_trim,4,nConds)
name_pas3 <- withinSubError(data_trim,3,nConds)
name_pas2 <- withinSubError(data_trim,2,nConds)
name_pas1 <- withinSubError(data_trim,1,nConds)
sem <- rbind(name_pas1$sem_cf,name_pas2$sem_cf,name_pas3$sem_cf,name_pas4$sem_cf)
tPlot <- rbind(name_pas1$y_sj,name_pas2$y_sj,name_pas3$y_sj,name_pas4$y_sj)
data_plot <- data_trim
data_plot[data_plot$studyResp3==1e+05,]$studyResp3 = 1
data_plot$studyResp3 <- as.factor(data_plot$studyResp3)
dfwc <- summarySEwithin(data_plot, measurevar="named"
, withinvars=c("condition","studyResp3"),
idvar="subject", na.rm=FALSE, conf.interval=.95)
dfwc
ggplot(dfwc, aes(x=studyResp3, y=N)) +
geom_bar(position=position_dodge(.9), colour="black", stat="identity") +
geom_errorbar(width=.25, aes(ymin=N-ci, ymax=N+ci)) +
facet_grid(. ~ condition ) +
xlab("PAS") +
ylab("proportion") +
ggtitle("proportion of each PAS in each condition")
aggregate(N~condition,data=dfwc,FUN='mean')
?norm
nomr(dfwc$N)
norm(dfwc$N)
norm(as.matrix(dfwc$N))
library(plyr)
ddply(dfwc,.condition,transform,prop=N/sum(N))
dfwc
DF<-ddply(dfwc,.(condition),transform,prop=N/sum(N))
DF
dfwc<-ddply(dfwc,.(condition),transform,prop=N/sum(N))
dfwc
ggplot(dfwc, aes(x=studyResp3, y=prop)) +
geom_bar(position=position_dodge(.9), colour="black", stat="identity") +
geom_errorbar(width=.25, aes(ymin=N-ci, ymax=N+ci)) +
facet_grid(. ~ condition ) +
xlab("PAS") +
ylab("proportion") +
ggtitle("proportion of each PAS in each condition")
ggplot(dfwc, aes(x=studyResp3, y=prop)) +
geom_bar(position=position_dodge(.9), colour="black", stat="identity") +
geom_errorbar(width=.25, aes(ymin=prop-ci, ymax=prop+ci)) +
facet_grid(. ~ condition ) +
xlab("PAS") +
ylab("proportion") +
ggtitle("proportion of each PAS in each condition")
wd <- getwd()
dataFile <- paste(wd, "/cfs_obj_2afc_ss1.dat", sep="")
# find the data that was generated from the matlab files
data <- read.csv(dataFile)
# add 1 to study resp because participants were instructed to use 0-3
data$studyResp = data$studyResp+1
data$studyResp2 = data$studyResp2+1
data$studyResp3 = data$studyResp3+1
data[data$studyResp3==1e+05,]$studyResp3 = 1
data$studyResp3 <- as.factor(data$studyResp3)
data[data$studyResp3==1e+05,]$studyResp3 = 1
data <- read.csv(dataFile)
data$studyResp = data$studyResp+1
data$studyResp2 = data$studyResp2+1
data$studyResp3 = data$studyResp3+1
data[data$studyResp3==1e+05,]$studyResp3 = 1
1e+05
10000
10000==1e+05
100000==1e+05
data
